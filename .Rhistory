)
)
ensemble <- c(
"GLM", "GBM", "GAM", "CTA", "ANN", "SRE",
"FDA", "MARS", "RF", "MAXENT", "MAXNET"
)
all_biomod2_algos <- switch(
alg,
ENS = ensemble,
match.arg(alg, ensemble)
)
bn <- "Mithraculus forceps"
alg <- "ENS"
cat(
"Début de routine\n",
"Espèce : ", bn, "\n",
"Algorithme : ", alg, "\n"
)
# alg <- "RF"
# alg <- "MAXENT"
# alg <- "ensemble"
# Nombre de répétitions (nombre de jeux de validation croisées)
CV_nb_rep <- 5
# nom du modèle
vec_name_model <- c(
paste0(tolower(alg), CV_nb_rep), "01", "global", "cpc"
)
pts_name_model <- paste(vec_name_model, collapse = ".")
# Données biologiques ----
# bn <- "Claremontiella nodulosa"
supfam <- species$superFamily[species$species == bn]
sp  <- pa[[bn]] %>% as.data.frame(xy = T)
binnam <- str_split(bn, " ")[[1]] %>%
lapply(substr, 1, 3) %>%
paste0(collapse = ".")
# jeux de données environnementales pour calibration du SDM ----
# carte globale des variables environnementales
clim_sub      <- cgc_sub[[supfam]][[bn]]
clim_proj_sub <- subset(climosaic, names(clim_sub))
# Données d'occurrences ----
bio <- here("data", "tidy", "bio", supfam, bn, "bio_global.rds") %>%
readRDS()
bio_info <- bio[, 1:6] %>% st_drop_geometry()
bio_data <- bio[, 7:ncol(bio)] %>% st_drop_geometry()
bio_data <- bio_data %>% select(all_of(names(clim_sub)))
bio      <- bio_info %>%
cbind(bio_data) %>%
st_as_sf(geometry = st_geometry(bio))
# Application de la fonction de production d'un SDM pour un seul algorithme
sdmOneAlgo2(
alg            = alg,
CV_nb_rep      = CV_nb_rep,
supfam         = supfam,
binnam         = binnam,
bn             = bn,
vec_name_model = vec_name_model,
bio            = bio,
clim_sub       = clim_proj_sub,
clim_proj_sub  = clim_proj_sub,
pts_name_model = pts_name_model
)
alg            = alg
CV_nb_rep      = CV_nb_rep
supfam         = supfam
binnam         = binnam
bn             = bn
vec_name_model = vec_name_model
bio            = bio
clim_sub       = clim_proj_sub
clim_proj_sub  = clim_proj_sub
pts_name_model = pts_name_model
modeling_id <- gsub(
" ",
".",
paste(
binnam,
paste(vec_name_model, collapse = " ")
)
)
# Niche écologique observée ----
clm <- bio %>%
filter(individualCount > 0) %>%
select(-c(type, id, scale, individualCount)) %>%
st_drop_geometry()
neo_data <- clm %>% select(-c(x, y))
neo_dens <- lapply(
names(neo_data),
\(varenv) {
p <- ggplot(data = neo_data, aes(x = get(varenv), col = 1, fill = 2)) +
geom_density(alpha = 0.6) +
scale_fill_viridis_c() +
scale_color_viridis_c() +
guides(fill = "none", col = "none") +
labs(x = varenv, y = "Densité")
}
)
neo_grph <- Reduce(`+`, neo_dens)
# Biais environnemental ----
# estimation du biais environnemental présent dans les données
qtl <- 0.01
myAlpha <- 0.5
plot_env_bias <- lapply(
names(neo_data),
\(varenv) {
phst <- ggplot() +
geom_histogram(
data = as.data.frame(clim_sub),
aes(x = get(varenv), y = after_stat(density), fill = "Grille environnementale"),
alpha = myAlpha,
bins = 30
) +
geom_histogram(
data = neo_data,
aes(x = get(varenv), y = after_stat(density), fill = "Occurrences de l'espèce"),
alpha = myAlpha,
bins = 30
) +
scale_fill_manual(values = c("green", "red")) +
xlab(varenv) +
ylab("Densité") +
scale_x_continuous(
limits = c(
min(
quantile(neo_data[[varenv]], qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], qtl, na.rm = T)
),
max(
quantile(neo_data[[varenv]], 1 - qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], 1 - qtl, na.rm = T)
)
)
) +
guides(fill = guide_legend(title = NULL)) +
theme(
text = element_text(size = 15),
legend.position = "bottom"
)
pbox_env <- ggplot() +
geom_boxplot(
data = as.data.frame(clim_sub),
aes(x = get(varenv)),
fill = "green",
col = "darkgreen",
alpha = 0.7
) +
xlab(varenv) +
scale_x_continuous(
limits = c(
min(
quantile(neo_data[[varenv]], qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], qtl, na.rm = T)
),
max(
quantile(neo_data[[varenv]], 1 - qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], 1 - qtl, na.rm = T)
)
)
) +
theme_void()
pbox_spe <- ggplot() +
geom_boxplot(
data = neo_data,
aes(x = get(varenv)),
fill = "red",
col = "darkred",
alpha = 0.7
) +
xlab(varenv) +
scale_x_continuous(
limits = c(
min(
quantile(neo_data[[varenv]], qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], qtl, na.rm = T)
),
max(
quantile(neo_data[[varenv]], 1 - qtl, na.rm = T),
quantile(as.data.frame(clim_sub)[[varenv]], 1 - qtl, na.rm = T)
)
)
) +
theme_void()
pbox_spe / pbox_env / phst + plot_layout(heights = c(0.1, 0.1, 0.8))
}
)
names(plot_env_bias) <- names(clim_sub)
# Chemins et dossiers de sauvegarde
path_models <- here("data", "analysis", "models")
makeMyDir(path_models)
path_supfam <- here(path_models, supfam)
makeMyDir(path_supfam)
path_species <- here(path_supfam, bn)
makeMyDir(path_species)
path_modid <- here(path_species, modeling_id)
makeMyDir(path_modid)
# Formatage des données pour le modèle ----
spec_data <- BIOMOD_FormatingData(
# Données initiales
resp.var       = bio$individualCount,
expl.var       = clim_sub,
resp.xy        = st_coordinates(bio) %>%
as_tibble() %>%  select(x = X, y = Y),
# Modalités de sauvegarde
dir.name       = path_species,
resp.name      = modeling_id,
# Gestion des occurrences multiples dans une cellule
filter.raster  = TRUE
)
# Paramétrage du modèle ----
biom_options <- BIOMOD_ModelingOptions(
MAXENT = list(
path_to_maxent.jar = here("scripts", "maxent", "maxent.jar")
)
)
ensemble <- c(
"GLM", "GBM", "GAM", "CTA", "ANN", "SRE",
"FDA", "MARS", "RF", "MAXENT", "MAXNET"
)
all_biomod2_algos <- switch(
alg,
ENS = ensemble,
match.arg(alg, ensemble)
)
print(
paste(
"Les algorithmes utilisés lors de cette modélisation sont :",
paste(all_biomod2_algos, collapse = ", ")
)
)
# Modélisation des habitats favorables selon une méthode ensembliste ----
# cl <- startMPIcluster()
# registerDoMPI(cl)
spec_models <- BIOMOD_Modeling(
bm.options      = biom_options,
bm.format       = spec_data,
modeling.id     = modeling_id,
models          = all_biomod2_algos,
CV.nb.rep       = CV_nb_rep,
CV.perc         = 0.8,
var.import      = 3
# nb.cpu          = cl$workerCount
)
# closeCluster()
# error avec "method(depth)"
# vérifier la longueur du nom du modèle
# Warning messages:
#   1: executing %dopar% sequentially: no parallel backend registered
# 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
# 3: glm.fit: fitted probabilities numerically 0 or 1 occurred                                                          Fitting terminated with step failure - check results carefully
# sauvegarde niche écologique/biais environnemental ----
path_neo <- here(path_modid, "nicheEcoObs")
makeMyDir(path_neo)
file_name <- binnam %>%
paste("ecological", "niche", "observed", sep = "_") %>%
paste0(".png")
ggexport(
plot = neo_grph,
filename = here(path_neo, file_name),
width = 2000,
height = 1000,
res = 200,
units = "px",
device = "png",
limitsize = F
)
path_biav <- here(path_modid, "biasEnv")
makeMyDir(path_biav)
lapply(
names(plot_env_bias),
\(varenv) {
file_name <- binnam %>%
paste("environmental", "bias", varenv, sep = "_") %>%
paste0(".png")
ggexport(
plot = plot_env_bias[[varenv]],
filename = here(path_biav, file_name),
width = 2000,
height = 1500,
res = 200,
units = "px",
device = "png",
limitsize = F
)
}
)
# Évaluation ----
# fichier d'accueil
path_eval <- here(path_modid, "eval")
makeMyDir(path_eval)
# get model evaluation scores
modScores <- get_evaluations(spec_models)
# sauvegarde
file_name <- gsub(" ", ".", bn) %>%
paste(pts_name_model, "evaluations", sep = "_") %>%
paste0(".csv")
write.csv(
modScores,
here(path_eval, file_name),
row.names = F,
fileEncoding = "UTF-16"
)
modScoresSummary01 <- modScores %>%
filter(run != "allRun") %>%
group_by(metric.eval) %>%
summarise(
cutoff_mean = mean(cutoff),
cutoff_stdv = sd(cutoff),
sensitivity_mean = mean(sensitivity),
sensitivity_stdv = sd(sensitivity),
specificity_mean = mean(specificity),
specificity_stdv = sd(specificity),
calibration_mean = mean(calibration),
calibration_stdv = sd(calibration),
validation_mean = mean(validation),
validation_stdv = sd(validation)
)
# sauvegarde
file_name <- gsub(" ", ".", bn) %>%
paste(pts_name_model, "evaluation", "summary", sep = "_") %>%
paste0(".csv")
write.csv(
modScoresSummary01,
here(path_eval, file_name),
row.names = F,
fileEncoding = "UTF-16"
)
# attention : moyenne des runs != indices calculés sur tous les runs
modScoresSummary02 <- modScores %>%
filter(run == "allRun")
file_name <- gsub(" ", ".", bn) %>%
paste(pts_name_model, "evaluation", "allRun", sep = "_") %>%
paste0(".csv")
write.csv(
modScoresSummary02,
here(path_eval, file_name),
row.names = F,
fileEncoding = "UTF-16"
)
# Graphique des évaluations ----
p1 <- bm_PlotEvalMean_gm(
bm.out      = spec_models,
metric.eval = c("ROC","TSS"),
group.by    = "algo",
dataset = "calibration",
do.plot = T,
main = NULL,
ylim = c(0, 1),
xlim = c(0, 1)
)
saveRDS(p1, here(path_eval, "TSSfROC_algo.rds"))
ggexport(
plot = p1$plot,
filename = here(path_eval, "TSSfROC_algo.png"),
width = 1000,
height = 800,
res = 200,
units = "px",
device = "png",
limitsize = F
)
p2 <- bm_PlotEvalMean_gm(
bm.out      = spec_models,
metric.eval = c("ROC","TSS"),
group.by    = "run",
dataset = "calibration",
do.plot = T,
main = NULL,
ylim = c(0, 1),
xlim = c(0, 1)
)
saveRDS(p2, here(path_eval, "TSSfROC_runs.rds"))
ggexport(
plot = p2$plot,
filename = here(path_eval, "TSSfROC_runs.png"),
width = 1000,
height = 800,
res = 200,
units = "px",
device = "png",
limitsize = F
)
p3 <- bm_PlotEvalMean_gm(
bm.out      = spec_models,
metric.eval = c("KAPPA","TSS"),
group.by    = "algo",
dataset = "calibration",
main = NULL,
ylim = c(0, 1),
xlim = c(0, 1)
)
saveRDS(p3, here(path_eval, "TSSfKAP_algo.rds"))
ggexport(
plot = p3$plot,
filename = here(path_eval, "TSSfKAP_algo.png"),
width = 1000,
height = 800,
res = 200,
units = "px",
device = "png",
limitsize = F
)
p4 <- bm_PlotEvalMean_gm(
bm.out      = spec_models,
metric.eval = c("KAPPA","TSS"),
group.by    = "run",
dataset = "calibration",
main = NULL,
ylim = c(0, 1),
xlim = c(0, 1)
)
saveRDS(p4, here(path_eval, "TSSfKAP_runs.rds"))
ggexport(
plot = p4$plot,
filename = here(path_eval, "TSSfKAP_runs.png"),
width = 1000,
height = 800,
res = 200,
units = "px",
device = "png",
limitsize = F
)
(spec_models_var_import <- get_variables_importance(spec_models))
# calculate the mean of variable importance by algorithm
var_importance <- dcast(
spec_models_var_import,
expl.var ~ algo,
fun.aggregate = mean,
value.var = "var.imp"
)
p5 <- if (alg != "ENS") {
ggplot() +
geom_col(
data = var_importance,
aes(
x = expl.var %>%
factor(
levels = expl.var[order(get(alg), decreasing = T)]
),
y = get(alg)
)
) +
xlab("Variable environnementale") +
ylab("Contribution (%)")
} else {
var_importance_ens <- var_importance %>%
add_column(median = apply(.[, -1], 1, median))
var_importance_ens$expl.var <- factor(
var_importance_ens$expl.var,
levels = var_importance_ens$expl.var[
order(var_importance_ens$median, decreasing = T)
]
)
var_importance_ens <- var_importance_ens %>%
select(-median) %>%
melt()
ggplot(
data = var_importance_ens,
aes(
x = expl.var,
y = value * 100
)
) +
geom_boxplot() +
xlab("Variable environnementale (médiane décroissante)") +
ylab("Contribution (%)")
}
ggexport(
plot = p5,
filename = here(path_eval, "contributions_variables.png"),
width = 1000,
height = 800,
res = 200,
units = "px",
device = "png",
limitsize = F
)
# Models response curves
# To do this we first have to load the produced models.
lapply(
all_biomod2_algos,
\(my_algo) {
glm_eval_strip <- biomod2::bm_PlotResponseCurves(
bm.out           = spec_models,
models.chosen    = BIOMOD_LoadModels(spec_models, algo = my_algo),
fixed.var        = "median",
main             = my_algo,
do.plot          = F
)
pout <- glm_eval_strip$plot +
guides(col = "none")
ggexport(
plot = pout,
filename = here(path_eval, paste0("response_curves", my_algo, ".png")),
width = 1000,
height = 800,
res = 100,
units = "px",
device = "png",
limitsize = F
)
}
)
# Ensemble modelling
all_ensemble_algos <- c("EMcv", "EMca","EMwmean")
names(all_ensemble_algos) <- all_ensemble_algos
spec_ensemble_models <- BIOMOD_EnsembleModeling(
bm.mod        = spec_models,
models.chosen = get_built_models(spec_models),
em.by         = "all",
em.algo       = all_ensemble_algos,
metric.select = "all"
)
spec_ensemble_models
